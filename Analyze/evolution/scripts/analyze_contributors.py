#!/usr/bin/env python3
"""
ç¬¬ä¸€é˜¶æ®µï¼šè´¡çŒ®è€…åˆ†æè„šæœ¬
åˆ†æè´¡çŒ®è€…åˆ†å¸ƒã€æ´»è·ƒåº¦ã€Gini ç³»æ•°ç­‰æŒ‡æ ‡
Author:ä½Ÿé›¨æ³½
"""

import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple


def load_commits(input_file: str) -> List[Dict]:
    """åŠ è½½ Commit æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def calculate_gini(values: List[int]) -> float:
    """
    è®¡ç®— Gini ç³»æ•° (è¡¡é‡ä¸å¹³ç­‰åº¦)
    0 = å®Œå…¨å¹³ç­‰ï¼Œ1 = å®Œå…¨ä¸å¹³ç­‰
    """
    sorted_vals = sorted(values)
    n = len(values)
    cumsum = sum((i + 1) * val for i, val in enumerate(sorted_vals))
    return (2 * cumsum) / (n * sum(values)) - (n + 1) / n


def analyze_contributors(commits: List[Dict], recent_months: int = 6) -> Dict:
    """
    åˆ†æè´¡çŒ®è€…æŒ‡æ ‡
    
    Args:
        commits: Commit åˆ—è¡¨
        recent_months: è®¡ç®—æ´»è·ƒè´¡çŒ®è€…çš„æ—¶é—´çª—å£ (æœˆ)
    
    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    print("\nğŸ” åˆ†æè´¡çŒ®è€…æ•°æ®...")
    
    # æ„å»º DataFrame
    df = pd.DataFrame(commits)
    df['date'] = pd.to_datetime(df['date'])
    
    # æå– stats ä¸­çš„ä»£ç å˜æ›´æ•°æ®
    df['insertions'] = df['stats'].apply(lambda x: x.get('additions', 0) if isinstance(x, dict) else 0)
    df['deletions'] = df['stats'].apply(lambda x: x.get('deletions', 0) if isinstance(x, dict) else 0)
    
    # åŸºç¡€ç»Ÿè®¡
    total_commits = len(df)
    unique_authors = df['author'].nunique()
    
    # ä½œè€…ç»Ÿè®¡
    author_stats = df.groupby('author').agg({
        'hash': 'count',  # Commit æ•°
        'insertions': 'sum',
        'deletions': 'sum',
        'date': ['min', 'max']
    }).round(2)
    
    author_stats.columns = ['commits', 'insertions', 'deletions', 'first_commit', 'last_commit']
    author_stats['code_change'] = author_stats['insertions'] + author_stats['deletions']
    author_stats = author_stats.sort_values('commits', ascending=False)
    
    # æ´»è·ƒè´¡çŒ®è€… (æœ€è¿‘ N ä¸ªæœˆ)
    # å¤„ç†æ—¶åŒºé—®é¢˜ï¼šå°† naive datetime è½¬æ¢ä¸º UTC
    recent_date = datetime.now() - timedelta(days=30*recent_months)
    recent_date_utc = recent_date.replace(tzinfo=None)  # ç§»é™¤æ—¶åŒºä¿¡æ¯ä»¥åŒ¹é…æ•°æ®
    recent_df = df[df['date'].dt.tz_localize(None) > recent_date_utc]
    active_authors = recent_df['author'].nunique()
    
    # æ ¸å¿ƒå›¢é˜Ÿåˆ†æ (å‰ 5% è´¡çŒ®è€…)
    core_team_size = max(1, int(unique_authors * 0.05))
    top_authors = author_stats.head(core_team_size)
    top_commits = top_authors['commits'].sum()
    top_concentration = (top_commits / total_commits) * 100
    
    # Gini ç³»æ•°
    gini = calculate_gini(author_stats['commits'].tolist())
    
    # è´¡çŒ®åˆ†å¸ƒåˆ†æ
    commit_counts = author_stats['commits'].tolist()
    
    analysis = {
        'summary': {
            'total_commits': int(total_commits),
            'unique_authors': int(unique_authors),
            'active_authors_6m': int(active_authors),
            'core_team_size': int(core_team_size),
            'avg_commits_per_author': round(total_commits / unique_authors, 2),
            'gini_coefficient': round(gini, 3)
        },
        'top_contributors': []
    }
    
    # Top 20 è´¡çŒ®è€…
    for rank, (author, row) in enumerate(author_stats.head(20).iterrows(), 1):
        analysis['top_contributors'].append({
            'rank': rank,
            'author': author,
            'commits': int(row['commits']),
            'percentage': round((row['commits'] / total_commits) * 100, 2),
            'insertions': int(row['insertions']),
            'deletions': int(row['deletions']),
            'code_change': int(row['code_change']),
            'first_commit': row['first_commit'].isoformat()[:10],
            'last_commit': row['last_commit'].isoformat()[:10]
        })
    
    # æµ“åº¦æŒ‡æ ‡
    analysis['concentration'] = {
        'top_5_percent_size': int(core_team_size),
        'top_5_percent_commits': int(top_commits),
        'top_5_percent_concentration': round(top_concentration, 2),
        'interpretation': 'High' if top_concentration > 70 else ('Medium' if top_concentration > 50 else 'Low')
    }
    
    print(f"âœ“ æ€»è´¡çŒ®è€…æ•°: {unique_authors}")
    print(f"âœ“ è¿‘ 6 ä¸ªæœˆæ´»è·ƒè´¡çŒ®è€…: {active_authors}")
    print(f"âœ“ Gini ç³»æ•°: {gini:.3f}")
    print(f"âœ“ å‰ 5% ({core_team_size} äºº) è´¡çŒ®ç‡: {top_concentration:.1f}%")
    
    return analysis, author_stats


def generate_visualization_data(author_stats: pd.DataFrame) -> Dict:
    """
    ç”Ÿæˆå¯è§†åŒ–æ•°æ®
    """
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–æ•°æ®...")
    
    viz_data = {
        'pareto': {
            'authors': [],
            'commits': [],
            'cumulative_percent': []
        },
        'distribution': {
            'bins': [0, 1, 5, 10, 20, 50, 100, 500, 1000, 5000],
            'counts': []
        }
    }
    
    # Pareto æ•°æ® (å‰ 50 ä¸ªè´¡çŒ®è€…)
    total = author_stats['commits'].sum()
    cumsum = 0
    for author, row in author_stats.head(50).iterrows():
        cumsum += row['commits']
        viz_data['pareto']['authors'].append(author)
        viz_data['pareto']['commits'].append(int(row['commits']))
        viz_data['pareto']['cumulative_percent'].append(
            round((cumsum / total) * 100, 2)
        )
    
    # åˆ†å¸ƒç›´æ–¹å›¾æ•°æ®
    commits_list = author_stats['commits'].tolist()
    bins = [0, 1, 5, 10, 20, 50, 100, 500, 1000, 5000]
    for i in range(len(bins) - 1):
        count = len([c for c in commits_list if bins[i] <= c < bins[i+1]])
        viz_data['distribution']['counts'].append({
            'range': f"{bins[i]}-{bins[i+1]}",
            'count': count
        })
    
    # æœ€åä¸€ä¸ª bin (5000+)
    count = len([c for c in commits_list if c >= bins[-1]])
    viz_data['distribution']['counts'].append({
        'range': f"{bins[-1]}+",
        'count': count
    })
    
    return viz_data


def save_analysis(analysis: Dict, author_stats: pd.DataFrame, 
                  output_dir: str = 'evolution/results') -> None:
    """ä¿å­˜åˆ†æç»“æœ"""
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜ JSON æ ¼å¼
    with open(f'{output_dir}/contributors_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {output_dir}/contributors_analysis.json")
    
    # ä¿å­˜ CSV æ ¼å¼ (ä¾¿äº Excel æŸ¥çœ‹)
    author_stats.to_csv(f'{output_dir}/contributors_ranking.csv', encoding='utf-8')
    print(f"ğŸ’¾ æ’åè¡¨å·²ä¿å­˜: {output_dir}/contributors_ranking.csv")
    
    # ä¿å­˜å¯è§†åŒ–æ•°æ®
    viz_data = generate_visualization_data(author_stats)
    with open(f'{output_dir}/visualization_data.json', 'w', encoding='utf-8') as f:
        json.dump(viz_data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ å¯è§†åŒ–æ•°æ®å·²ä¿å­˜: {output_dir}/visualization_data.json")


def print_report(analysis: Dict) -> None:
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ è´¡çŒ®è€…åˆ†ææŠ¥å‘Š")
    print("=" * 70)
    
    summary = analysis['summary']
    print(f"\nã€åŸºç¡€ç»Ÿè®¡ã€‘")
    print(f"  æ€» Commit æ•°:        {summary['total_commits']:,}")
    print(f"  ç‹¬ç«‹è´¡çŒ®è€…æ•°:        {summary['unique_authors']}")
    print(f"  è¿‘ 6 ä¸ªæœˆæ´»è·ƒè´¡çŒ®è€…:  {summary['active_authors_6m']}")
    print(f"  å¹³å‡æäº¤æ•°/äºº:        {summary['avg_commits_per_author']}")
    
    print(f"\nã€é›†ä¸­åº¦æŒ‡æ ‡ã€‘")
    print(f"  Gini ç³»æ•°:           {summary['gini_coefficient']} " + 
          f"({'ä½å¹³ç­‰' if summary['gini_coefficient'] > 0.7 else ('ä¸­ç­‰' if summary['gini_coefficient'] > 0.5 else 'é«˜å¹³ç­‰')})")
    
    conc = analysis['concentration']
    print(f"  æ ¸å¿ƒå›¢é˜Ÿè§„æ¨¡:        {conc['top_5_percent_size']} äºº")
    print(f"  æ ¸å¿ƒå›¢é˜Ÿè´¡çŒ®ç‡:      {conc['top_5_percent_concentration']}%")
    
    print(f"\nã€Top 10 è´¡çŒ®è€…ã€‘")
    print(f"  {'æ’å':<5} {'ä½œè€…':<20} {'æäº¤æ•°':<10} {'å æ¯”':<8} {'ä»£ç é‡':<10}")
    print(f"  {'-'*60}")
    for contributor in analysis['top_contributors'][:10]:
        print(f"  {contributor['rank']:<5} {contributor['author']:<20} "
              f"{contributor['commits']:<10} {contributor['percentage']:<7}% "
              f"{contributor['code_change']:<10}")
    
    print("\n" + "=" * 70)


def main():
    # ç›´æ¥å®šä¹‰è¾“å…¥è¾“å‡ºè·¯å¾„
    INPUT_FILE = 'data/all_commits.json'  # åˆå¹¶åçš„æ‰€æœ‰ commit æ•°æ®
    OUTPUT_DIR = 'results'                # åˆ†æç»“æœè¾“å‡ºç›®å½•
    RECENT_MONTHS = 6                     # æ´»è·ƒè´¡çŒ®è€…æ—¶é—´çª—å£(æœˆ)
    
    print("=" * 60)
    print("ğŸ“Š MaxKB è´¡çŒ®è€…åˆ†æ")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"ğŸ• æ´»è·ƒæœŸ: æœ€è¿‘ {RECENT_MONTHS} ä¸ªæœˆ")
    print()
    
    # åŠ è½½æ•°æ®
    commits = load_commits(INPUT_FILE)
    
    # åˆ†æ
    analysis, author_stats = analyze_contributors(commits, RECENT_MONTHS)
    
    # ä¿å­˜ç»“æœ
    save_analysis(analysis, author_stats, OUTPUT_DIR)
    
    # æ‰“å°æŠ¥å‘Š
    print_report(analysis)
    
    print("\nâœ… è´¡çŒ®è€…åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()
