#!/usr/bin/env python3
"""
ç¬¬ä¸€é˜¶æ®µï¼šCommit æ•°æ®é‡‡é›†è„šæœ¬
ä½¿ç”¨ PyDriller ä»æœ¬åœ° Git ä»“åº“æå–æ‰€æœ‰ Commit ä¿¡æ¯
Author:ä½Ÿé›¨æ³½
"""

import json
import argparse
from datetime import datetime
from pathlib import Path
from pydriller import Repository
from typing import List, Dict


def fetch_commits(repo_path: str, since: str = None, until: str = None) -> List[Dict]:
    """
    ä» Git ä»“åº“æå–æ‰€æœ‰ Commit æ•°æ®
    
    Args:
        repo_path: Git ä»“åº“æœ¬åœ°è·¯å¾„
        since: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        until: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    
    Returns:
        æå–çš„ Commit åˆ—è¡¨
    """
    commits_list = []
    
    print(f"ğŸ“¦ æ­£åœ¨æ‰«æä»“åº“: {repo_path}")
    
    try:
        # å¤„ç†æ—¶é—´èŒƒå›´å‚æ•°
        if since and until:
            repo = Repository(repo_path, since=since, to=until)
        elif since:
            repo = Repository(repo_path, since=since)
        elif until:
            repo = Repository(repo_path, to=until)
        else:
            repo = Repository(repo_path)
        total = 0
        
        # éå†æ‰€æœ‰ commits
        for commit in repo.traverse_commits():
            total += 1
            
            # æ„å»º Commit æ•°æ®
            commit_data = {
                'hash': commit.hash,
                'author': commit.author.name,
                'author_email': commit.author.email,
                'date': commit.committer_date.isoformat(),
                'message': commit.msg,
                'insertions': commit.insertions,
                'deletions': commit.deletions,
                'files_changed': len(commit.modified_files),
                'is_merge': commit.merge,
                'files': []
            }
            
            # æå–ä¿®æ”¹çš„æ–‡ä»¶
            for file in commit.modified_files:
                commit_data['files'].append({
                    'filename': file.filename,
                    'added_lines': file.added_lines,
                    'deleted_lines': file.deleted_lines,
                    'change_type': file.change_type.name
                })
            
            commits_list.append(commit_data)
            
            # è¿›åº¦æ˜¾ç¤º
            if total % 100 == 0:
                print(f"  âœ“ å·²å¤„ç† {total} ä¸ª Commit...")
        
        print(f"âœ… æ€»å…±æå– {total} ä¸ª Commit")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        raise
    
    return commits_list


def filter_bots(commits: List[Dict]) -> List[Dict]:
    """
    è¿‡æ»¤æ‰æœºå™¨äººè´¦æˆ·çš„æäº¤
    """
    bots = ['dependabot', 'renovate', 'codecov', 'github-actions', 'facebook-github-bot']
    
    filtered = [
        c for c in commits 
        if not any(bot in c['author'].lower() for bot in bots)
    ]
    
    removed = len(commits) - len(filtered)
    if removed > 0:
        print(f"ğŸ¤– å·²è¿‡æ»¤ {removed} ä¸ªæœºå™¨äººæäº¤")
    
    return filtered


def merge_duplicate_authors(commits: List[Dict]) -> tuple[List[Dict], Dict]:
    """
    åˆå¹¶åŒä¸€ä½œè€…çš„é‡å¤é‚®ç®±
    è¿”å›: (æ¸…æ´åçš„æäº¤åˆ—è¡¨, ä½œè€…æ˜ å°„è¡¨)
    """
    author_mapping = {}
    
    # æ„å»ºä½œè€…æ˜ å°„ï¼ˆæ‰‹åŠ¨å®šä¹‰å·²çŸ¥çš„é‡å¤ï¼‰
    manual_mapping = {
        # ç¤ºä¾‹: 'old_email@example.com': 'canonical_name'
    }
    
    # è‡ªåŠ¨æ£€æµ‹ï¼šç›¸åŒé‚®ç®±åŸŸä½†ä¸åŒæœ¬åœ°åçš„ä½œè€…
    author_by_email = {}
    for commit in commits:
        email = commit['author_email']
        name = commit['author']
        
        if email not in author_by_email:
            author_by_email[email] = name
        else:
            # åŒä¸€é‚®ç®±ï¼Œä¸åŒåå­—æ—¶åˆå¹¶
            existing_name = author_by_email[email]
            if existing_name != name and email not in manual_mapping:
                print(f"âš ï¸  å‘ç°é‡å¤ä½œè€…: '{name}' å’Œ '{existing_name}' (é‚®ç®±: {email})")
                # ä¿ç•™æœ€é•¿çš„åå­—
                if len(name) > len(existing_name):
                    author_mapping[existing_name] = name
                    author_by_email[email] = name
    
    # åº”ç”¨æ˜ å°„
    for commit in commits:
        if commit['author'] in author_mapping:
            commit['author'] = author_mapping[commit['author']]
    
    print(f"âœ“ åˆå¹¶åçš„ä½œè€…æ˜ å°„: {len(author_mapping)} æ¡")
    
    return commits, author_mapping


def save_commits(commits: List[Dict], output_path: str) -> None:
    """ä¿å­˜ Commit æ•°æ®åˆ°æ–‡ä»¶"""
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(commits, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")


def generate_summary(commits: List[Dict]) -> Dict:
    """ç”Ÿæˆ Commit æ•°æ®æ‘˜è¦"""
    if not commits:
        return {}
    
    dates = [datetime.fromisoformat(c['date']) for c in commits]
    
    summary = {
        'total_commits': len(commits),
        'unique_authors': len(set(c['author'] for c in commits)),
        'date_range': {
            'start': min(dates).isoformat(),
            'end': max(dates).isoformat()
        },
        'total_insertions': sum(c['insertions'] for c in commits),
        'total_deletions': sum(c['deletions'] for c in commits),
        'files_touched': len(set(f['filename'] for c in commits for f in c['files'])),
        'merge_commits': len([c for c in commits if c['is_merge']])
    }
    
    return summary


def main():
    # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
    project_root = Path(__file__).parent.parent.parent.absolute()
    default_repo_path = project_root / "æºä»£ç "
    
    parser = argparse.ArgumentParser(
        description='ä» Git ä»“åº“æå– Commit æ•°æ®'
    )
    parser.add_argument(
        '--repo-path', 
        default=str(default_repo_path),  # é»˜è®¤æŒ‡å‘ MaxKB æºä»£ç ç›®å½•
        help=f'Git ä»“åº“æœ¬åœ°è·¯å¾„ (é»˜è®¤: {default_repo_path})'
    )
    parser.add_argument(
        '--output-file',
        default='data/maxkb_commits.json',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: data/maxkb_commits.json)'
    )
    parser.add_argument(
        '--since',
        help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD), é»˜è®¤ä¸ºæ•´ä¸ªå†å²'
    )
    parser.add_argument(
        '--until',
        help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--filter-bots',
        action='store_true',
        default=True,
        help='è¿‡æ»¤æœºå™¨äººè´¦æˆ· (é»˜è®¤: True)'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ MaxKB Commit æ•°æ®é‡‡é›†å·¥å…·")
    print("=" * 60)
    
    # é‡‡é›†æ•°æ®
    commits = fetch_commits(args.repo_path, args.since, args.until)
    
    # æ•°æ®æ¸…æ´—
    if args.filter_bots:
        commits = filter_bots(commits)
    
    commits, author_mapping = merge_duplicate_authors(commits)
    
    # ç”Ÿæˆæ‘˜è¦
    summary = generate_summary(commits)
    print("\nğŸ“Š æ•°æ®æ‘˜è¦:")
    print(f"  â€¢ æ€» Commit æ•°: {summary['total_commits']}")
    print(f"  â€¢ ç‹¬ç«‹ä½œè€…æ•°: {summary['unique_authors']}")
    print(f"  â€¢ æ—¶é—´èŒƒå›´: {summary['date_range']['start'][:10]} è‡³ {summary['date_range']['end'][:10]}")
    print(f"  â€¢ ä»£ç å¢åŠ : {summary['total_insertions']:,} è¡Œ")
    print(f"  â€¢ ä»£ç åˆ é™¤: {summary['total_deletions']:,} è¡Œ")
    print(f"  â€¢ ä¿®æ”¹æ–‡ä»¶æ•°: {summary['files_touched']}")
    print(f"  â€¢ åˆå¹¶æäº¤æ•°: {summary['merge_commits']}")
    
    # ä¿å­˜æ•°æ®
    save_commits(commits, args.output_file)
    
    # ä¿å­˜æ‘˜è¦
    summary_file = args.output_file.replace('.json', '_summary.json')
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"ğŸ’¾ æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
    
    print("\nâœ… æ•°æ®é‡‡é›†å®Œæˆï¼")


if __name__ == '__main__':
    main()
